{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM658RBOUaTldflZjT2eplr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vocaltrainer/pipeline_woo/blob/main/woo_pipeline(%EB%B9%84%EC%A0%95%ED%98%95).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 경로"
      ],
      "metadata": {
        "id": "m-4RV1y3L-zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/'\n",
        "train_path = data_path+'train/'\n",
        "valid_path = data_path+'val/'\n",
        "test_path = data_path+'test/'"
      ],
      "metadata": {
        "id": "2sapKullMF3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 읽기"
      ],
      "metadata": {
        "id": "wPmiBt27P1jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(valid_path)\n",
        "test = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "kgJX6O0EP3Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA(비정형 data)"
      ],
      "metadata": {
        "id": "dEfSFAgMb1Ww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 수"
      ],
      "metadata": {
        "id": "wZictRm7MJqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "디렉터리가 여러개 있는 경우"
      ],
      "metadata": {
        "id": "w9SLUsf4QJiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "print(f'train data 수: {len(glob(train_path+\"*/*\"))}')\n",
        "print(f'valid data 수: {len(glob(valid_path+\"*/*\"))}')\n",
        "print(f'test data 수: {len(glob(test_path+\"*/*\"))}')"
      ],
      "metadata": {
        "id": "TA63Mxn8MOGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "한 csv파일인 경우"
      ],
      "metadata": {
        "id": "YoBov4q9QOu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, test.shape"
      ],
      "metadata": {
        "id": "y2UVxdGGQQli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 라벨 분포"
      ],
      "metadata": {
        "id": "J454kOxIMQxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_list = [train_path,valid_path,test_path]\n",
        "normal = []\n",
        "pneu = []\n",
        "for path in path_list:\n",
        "    normal.extend(glob(path+'NORMAL/*'))\n",
        "    pneu.extend(glob(path+'PNEUMONIA/*'))\n",
        "print(f'normal 수: {len(normal)}')\n",
        "print(f'pneumonia 수: {len(pneu)}')"
      ],
      "metadata": {
        "id": "TmiURkY_MWCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "label = ['normal','pneumonia']\n",
        "plt.pie([len(normal),len(pneu)],labels=label,autopct='%.1f')"
      ],
      "metadata": {
        "id": "HY0sJI5XMZUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 이름으로부터 이미지 읽기"
      ],
      "metadata": {
        "id": "Bka81k9tMpPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def read_image(img_id):\n",
        "        img_path = f'{data_path}/images/{img_id}.jpg'\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        return image"
      ],
      "metadata": {
        "id": "6-9YAKhJQle_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 열(이미지 이름) -> 열(이미지) 로 변환"
      ],
      "metadata": {
        "id": "Ruzm3tgLQtpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_id = multi['image_id'].reset_index()\n",
        "multi_img = multi_id['image_id'].apply(read_image)"
      ],
      "metadata": {
        "id": "9nwMmfXLRE5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 열(이미지)의 RGB 채널 분리"
      ],
      "metadata": {
        "id": "51y3UzI2RJh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "red_values = [np.mean(multi_img[idx][:,:,0]) for idx in range(len(multi_id))]\n",
        "green_values = [np.mean(multi_img[idx][:,:,1]) for idx in range(len(multi_id))]\n",
        "blue_values = [np.mean(multi_img[idx][:,:,2]) for idx in range(len(multi_id))]\n",
        "values = [np.mean(multi_img[idx]) for idx in range(len(multi_id))]"
      ],
      "metadata": {
        "id": "V6Xu8_wyROUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전체 데이터의 RGB 채널별 픽셀 분포"
      ],
      "metadata": {
        "id": "ZJu9BjE-RRYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "fig, ax = plt.subplots(2,2,figsize=(15,15))\n",
        "sns.distplot(values,ax=ax[0,0])\n",
        "sns.distplot(red_values, ax=ax[0,1])\n",
        "sns.distplot(green_values, ax=ax[1,0])\n",
        "sns.distplot(blue_values, ax=ax[1,1])\n",
        "\n",
        "ax[0,0].set_title(\" multi_values(rgb)\")\n",
        "ax[0,1].set_title(\"red\")\n",
        "ax[1,0].set_title(\"green\")\n",
        "ax[1,1].set_title(\"blue\")"
      ],
      "metadata": {
        "id": "NdL-usyjRaDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지에서 객체 탐지(Canny)및 출력"
      ],
      "metadata": {
        "id": "9iQ4j_yyU5I0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "탐지"
      ],
      "metadata": {
        "id": "FN3zFCoYVjzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_and_cut(img):\n",
        "    emb_img = img.copy()\n",
        "    edges = cv2.Canny(img, 250, 300)\n",
        "    edge_coors = []\n",
        "    for i in range(edges.shape[0]):\n",
        "        for j in range(edges.shape[1]):\n",
        "            if edges[i][j] != 0:\n",
        "                edge_coors.append((i, j))\n",
        "\n",
        "    row_min = edge_coors[np.argsort([coor[0] for coor in edge_coors])[0]][0]\n",
        "    row_max = edge_coors[np.argsort([coor[0] for coor in edge_coors])[-1]][0]\n",
        "    col_min = edge_coors[np.argsort([coor[1] for coor in edge_coors])[0]][1]\n",
        "    col_max = edge_coors[np.argsort([coor[1] for coor in edge_coors])[-1]][1]\n",
        "    new_img = img[row_min:row_max, col_min:col_max]\n",
        "\n",
        "    emb_img[row_min-10:row_min+10, col_min:col_max] = [255, 0, 0]\n",
        "    emb_img[row_max-10:row_max+10, col_min:col_max] = [255, 0, 0]\n",
        "    emb_img[row_min:row_max, col_min-10:col_min+10] = [255, 0, 0]\n",
        "    emb_img[row_min:row_max, col_max-10:col_max+10] = [255, 0, 0]\n",
        "\n",
        "    return emb_img"
      ],
      "metadata": {
        "id": "ZvKX8uZIVhxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력"
      ],
      "metadata": {
        "id": "4HLqx_PeVm-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image_bb(img_ids, rows=2, cols=3):\n",
        "    #assert len(img_ids) <=rows*cols\n",
        "    f, ax = plt.subplots(rows, cols,figsize=(15,8))\n",
        "\n",
        "    for idx,img_id in enumerate(img_ids):\n",
        "        img_path = f'{data_path}/images/{img_id}.jpg'\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        ax[0,idx].imshow(image)\n",
        "        ax[1,idx].imshow(edge_and_cut(image))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qJ7i9E6QVoVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last = multi_id['image_id'][-3:].tolist()\n",
        "show_image_bb(last)"
      ],
      "metadata": {
        "id": "E5t_Jy8JVqlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##경로로부터 이미지 출력(6개 이미지)"
      ],
      "metadata": {
        "id": "iX0vJj3uMfv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def show_image(img_ids, rows=2, cols=3):\n",
        "    #assert len(img_ids) <=rows*cols\n",
        "    f, ax = plt.subplots(rows, cols,figsize=(15,8))\n",
        "\n",
        "    for idx,img_id in enumerate(img_ids):\n",
        "        img_path = img_ids[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        ax[idx//3,idx%3].imshow(image)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MjTbo-OJMjfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_normal = list(normal[-6:])\n",
        "show_image(last_normal)"
      ],
      "metadata": {
        "id": "m-TH1JUgMqOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시드값 고정(재현성) 및 세팅"
      ],
      "metadata": {
        "id": "uuJO5n_KMrhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "seed=50\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic=True\n",
        "torch.backends.cudnn.benchmark=False\n",
        "torch.backends.cudnn.enabled=False"
      ],
      "metadata": {
        "id": "3a6Jai1AMvey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "fsQbrHhaMzUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train_test_split(stratify)"
      ],
      "metadata": {
        "id": "TwgZl_izV7IA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "stratify로 타깃값이 골고루 분포되도록 분리"
      ],
      "metadata": {
        "id": "V4KW0I29WCqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#stratify로 타깃값이 골고루 분포되도록 분리\n",
        "train,valid = train_test_split(train,test_size=0.1,\n",
        "                               stratify=train[['healthy','multiple_diseases',\n",
        "                                               rust','scab']],\n",
        "                               random_state=50)"
      ],
      "metadata": {
        "id": "lpSzgU9VWJC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data augmentation, dataset 생성"
      ],
      "metadata": {
        "id": "q_ZkDefLNjwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디렉터리로 라벨링이 되있는 경우"
      ],
      "metadata": {
        "id": "CywbjUi5WWe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform_train = transforms.Compose([transforms.Resize((250,250)),\n",
        "                                     transforms.CenterCrop(180),\n",
        "                                     transforms.RandomHorizontalFlip(0.5),\n",
        "                                     transforms.RandomVerticalFlip(0.2),\n",
        "                                     trnasforms.RandomRotation(20),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.485,0.456,0.406),\n",
        "                                                         (0.229,0.224,0.255))])   #imageNet이 학습한 각 채널의 평균과 표준편차. 이를 사용하는것이 성능에 도움이됨\n",
        "\n",
        "transform_test = transforms.Compose([transforms.Resize(250,250),\n",
        "                                     transforms.CenterClip(180),\n",
        "                                     transforms.ToTensor(),\n",
        "\n",
        "                                     transforms.Normalize((0.485,0.456,0.406),\n",
        "                                                         (0.229,0.224,0.255))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "iNwS3kIBdBDb",
        "outputId": "a9437ff2-6903-4ef5-c8a1-556f23575ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-421d6af26df7>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    transforms.Normalize()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "#albumentation 쓰면 오류. torchvision.transforms 써야 함.\n",
        "#라벨링값이 같은 데이터들이 같은 디렉터리에 모여있어야 ImageFolder 쓸 수 있음.\n",
        "\n",
        "datasets_train = ImageFolder(root=train_path, transform = transform_train)\n",
        "datasets_test = ImageFolder(root=test_path,transform = transform_test)"
      ],
      "metadata": {
        "id": "b9sV2yfqM_Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그렇지 않은 경우 사용자 정의 dataset 생성"
      ],
      "metadata": {
        "id": "2PkREkL7WVtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "albumentations : torchvision.transforms보다 많은 기능 지원"
      ],
      "metadata": {
        "id": "pZuzTSkzdPMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "metadata": {
        "id": "7sWyj6-VdSrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = A.Compose([\n",
        "    A.Resize(450,650),                                       #이미지를 크게 조정하면 성능이 좋다고 함. 단, 그만큼 리소스가 커짐\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2,             #brightness:밝기, contrast:대비, p:확률\n",
        "                          contrast_limit=0.2,p=0.3),\n",
        "    A.VerticalFlip(p=0.2),                                   #상하 대칭 변환\n",
        "    A.HorizontalFlip(p=0.5),                                 #좌우 대칭 변환\n",
        "    A.ShiftScaleRotate(                                      #이동, 스케일링, 회전각도 조절\n",
        "    shift_limit=0.1,\n",
        "    scale_limit=0.2,\n",
        "    rotate_limit=30,p=0.3),\n",
        "    A.OneOf([A.Emboss(p=1),                                  #양각화, 날카롭게 만드는 효과, 블러 효과 중 한가지를 적용\n",
        "            A.Sharpen(p=1),\n",
        "            A.Blur(p=1)],p=0.3),\n",
        "    A.PiecewiseAffine(p=0.3),                                #어파인 변환기(이동,확대/축소, 회전등으로 이미좀양을 전체적으로 바꿈)\n",
        "    A.Normalize(),                                           #정규화\n",
        "    ToTensorV2()                                             #이미지데이터를 텐서로 변환\n",
        "\n",
        "])\n",
        "\n",
        "transform_test = A.Compose([A.Resize(450,650),    #Train data와 크기를 같게\n",
        "                           A.Normalize(),         #픽셀값 범위도 같게\n",
        "                           ToTensorV2()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "OlqHPbyZdTQw",
        "outputId": "e0a69391-37b3-4dde-a6e3-270a153da31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-df12107faa0b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transform_train = A.Compose([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m650\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                       \u001b[0;31m#이미지를 크게 조정하면 성능이 좋다고 함. 단, 그만큼 리소스가 커짐\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     A.RandomBrightnessContrast(brightness_limit=0.2,             #brightness:밝기, contrast:대비, p:확률\n\u001b[1;32m      4\u001b[0m                           contrast_limit=0.2,p=0.3),\n\u001b[1;32m      5\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVerticalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                   \u001b[0;31m#상하 대칭 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df,img_dir='/',transform=None, is_test=False):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img_id = self.df.iloc[idx,0]\n",
        "        img_path = self.img_dir+img_id+'.jpg'\n",
        "        img = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image =self.transform(image=image)['image']  #albumentation 사용할 것임\n",
        "\n",
        "        if self.is_test:\n",
        "            return image\n",
        "        else:\n",
        "            label = np.argmax(self.df.iloc[idx,1:5])\n",
        "            return image, label"
      ],
      "metadata": {
        "id": "DvG7moFbXW5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = f'{data_path}/images/'\n",
        "dataset_train = ImageDataset(train,img_dir=img_dir,transform=transform_train)\n",
        "dataset_valid = ImageDataset(valid,img_dir=img_dir,transform=transform_test)\n",
        "dataset_test = ImageDataset(test, img_dir = img_dir,\n",
        "                           transform = transform_test, is_test=True)"
      ],
      "metadata": {
        "id": "rKn_qt9QYBqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dataloader 시드고정(멀티프로세싱을 위해)"
      ],
      "metadata": {
        "id": "59vI3JahNLEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed()%2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)"
      ],
      "metadata": {
        "id": "HW39UUp_M_AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataloader 생성"
      ],
      "metadata": {
        "id": "Z5_xHItfNqWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 4\n",
        "loader_train = DataLoader(datasets_train, batch_size = batch_size, shuffle=True, worker_init_fn = seed_worker,\n",
        "                         generator = g, num_workers=2)\n",
        "\n",
        "loader_valid = DataLoader(datasets_valid, batch_size = batch_size, shuffle=False, worker_init_fn = seed_worker,\n",
        "                          generator = g, num_workers = 2)\n",
        "loader_test = DataLoader(dataset_test, batch_size=batch_size,\n",
        "                           shuffle=False, worker_init_fn=seed_worker,generator=g,num_workers=2)"
      ],
      "metadata": {
        "id": "q5-Bzl2lM_Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNet 모델 생성"
      ],
      "metadata": {
        "id": "0q9d96SbYkBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet-pytorch==0.7.1"
      ],
      "metadata": {
        "id": "hQsygE3KM_IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b7',num_classes=4)  #num_classes: 현 competition의 출력값개수는 4개!\n",
        "model = model.to(device) #GPU 할당"
      ],
      "metadata": {
        "id": "IEbOIf7-M_K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고로 아래와 같은 방법으로 EfficientNet의 마지막 FC는 수정이 가능하다."
      ],
      "metadata": {
        "id": "E9bphaaTYrGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "\n",
        "# model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "# model._fc=nn.Sequential(nn.Linear(model._fc.in_features,model._fc.out_features),\n",
        "#                         nn.ReLU(),\n",
        "#                         nn.Dropout(0.5),\n",
        "#                         nn.Linear(Model._fc.out_features,4)\n",
        "#                        )"
      ],
      "metadata": {
        "id": "hw7hWsatYtFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loss, optimizer 설정"
      ],
      "metadata": {
        "id": "V_T-f3WLZgj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.00006,weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "2mtjStUFYtgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "FOdR1kJhZof0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm.notebook import tqdm\n",
        "epochs=5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()              #train 상태로 설정\n",
        "    epoch_train_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(loader_train):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        epoch_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'epoch[{epoch+1}/{epochs}] -train 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n",
        "\n",
        "    #미니배치 단위로 검증 수행\n",
        "    model.eval()\n",
        "    epoch_valid_loss=0\n",
        "    preds_list=[]\n",
        "    true_onehot_list=[]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader_valid:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs=model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            epoch_valid_loss += loss.item()\n",
        "\n",
        "            preds = torch.softmax(outputs.cpu(),dim=1).numpy()\n",
        "             #원핫인코딩, device='cuda'해줘야 함\n",
        "            true_onehot = torch.eye(4,device='cuda')[labels].cpu().numpy()\n",
        "\n",
        "            preds_list.extend(preds)\n",
        "            true_onehot_list.extend(true_onehot)\n",
        "\n",
        "        print(f'epoch[{epoch+1}/{epochs}] -valid 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f} / valid ROC_AUC : {roc_auc_score(true_onehot_list,preds_list):.4f}')"
      ],
      "metadata": {
        "id": "dx6qtTHMZqll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "F0fY_t-CaRBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "preds = np.zeros((len(test),4))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i,images in enumerate(loader_test):\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds_part = torch.softmax(outputs.cpu(),dim=1).squeeze().numpy()\n",
        "        preds[i*batch_size:(i+1)*batch_size]+=preds_part"
      ],
      "metadata": {
        "id": "FEYbqhTxaTkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#기타. 캐글 submission"
      ],
      "metadata": {
        "id": "PSC7hu8Oazus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n",
        "submission = pd.read_csv(data_path+'sample_submission.csv')"
      ],
      "metadata": {
        "id": "x7iGQeMmbJ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission[['healthy','multiple_diseases','rust','scab']]=preds"
      ],
      "metadata": {
        "id": "VPa-IZx6azN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('submission1.csv',index=False)"
      ],
      "metadata": {
        "id": "rf-6zi4za8Oq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
